{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government. Supreme exective power derives from a mandate from the masses, not from some farcial aquatic ceremony.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DENNIS - : - Listen - , - strange - women - lying - in - ponds - distributing - swords - is - no - basis - for - a - system - of - government - . - Supreme - exective - power - derives - from - a - mandate - from - the - masses - , - not - from - some - farcial - aquatic - ceremony - .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "\" - \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'woman',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distributing',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'exective',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcial',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tokens = [wnl.lemmatize(t) for t in tokens]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Tokens | Lemmatized          \n",
      "----------------------------------------\n",
      "              DENNIS | DENNIS              \n",
      "                   : | :                   \n",
      "              Listen | Listen              \n",
      "                   , | ,                   \n",
      "             strange | strange             \n",
      "               women | woman               \n",
      "               lying | lying               \n",
      "                  in | in                  \n",
      "               ponds | pond                \n",
      "        distributing | distributing        \n",
      "              swords | sword               \n",
      "                  is | is                  \n",
      "                  no | no                  \n",
      "               basis | basis               \n",
      "                 for | for                 \n",
      "                   a | a                   \n",
      "              system | system              \n",
      "                  of | of                  \n",
      "          government | government          \n",
      "                   . | .                   \n",
      "             Supreme | Supreme             \n",
      "            exective | exective            \n",
      "               power | power               \n",
      "             derives | derives             \n",
      "                from | from                \n",
      "                   a | a                   \n",
      "             mandate | mandate             \n",
      "                from | from                \n",
      "                 the | the                 \n",
      "              masses | mass                \n",
      "                   , | ,                   \n",
      "                 not | not                 \n",
      "                from | from                \n",
      "                some | some                \n",
      "             farcial | farcial             \n",
      "             aquatic | aquatic             \n",
      "            ceremony | ceremony            \n",
      "                   . | .                   \n"
     ]
    }
   ],
   "source": [
    "print(\"{:>20} | {:<20}\".format(\"Tokens\", \"Lemmatized\"))\n",
    "print(\"-\"*40)\n",
    "for t, lt in zip(tokens, lemmatized_tokens):\n",
    "    print(\"{:>20} | {:<20}\".format(t, lt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artofai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
