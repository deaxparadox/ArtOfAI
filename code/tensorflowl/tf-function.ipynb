{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 2, eager execution is turned on by default.\n",
    "\n",
    "- `tf.function` to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflows graphs out of Python code. This will help you create performant and portable models, and it is required to use `SavedModel`.\n",
    "\n",
    "- The main takeaways and recommendations are:\n",
    "\n",
    "    1. Debug in eager mode, then decorate with `@tf.function`.\n",
    "    2. Don't rely on Python side effects like object mutation or list appends.\n",
    "    3. `tf.function` works best with TensorFlow ops; NumPy and Python calls are converted to constants.\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 20:25:41.307766: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 20:25:41.314216: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 20:25:41.334116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744210541.367803   20415 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744210541.377940   20415 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744210541.400663   20415 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744210541.400693   20415 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744210541.400696   20415 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744210541.400699   20415 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 20:25:41.409067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to demonstrate the kinds of errors you might encounter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper code to demonstrate the kinds of errors you might encounter.\n",
    "@contextlib.contextmanager\n",
    "def assert_raise(error_class):\n",
    "    try:\n",
    "        yield\n",
    "    except error_class as e:\n",
    "        print(\"Caught expected exception \\n {}:\".format(error_class))\n",
    "        traceback.print_exc(limit=2)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    else:\n",
    "        raise Exception(\"Expected {} to be raised by error was raised!\".format(error_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "\n",
    "#### Usage\n",
    "\n",
    "A `tf.function` that you define (for example by applying the `@tf.function` decorator) is just like a core TensorFlow operation: You can executed it eagerly; you can compute gradients; and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 20:25:46.030565: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The decorator converts `add` into a `PolymorphicFunction`\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# [[2., 2.], [2., 2.]]\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.function`s inside other `tf.function`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "    return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.function`s can be faster than eager code, especially for graphs with many small ops. But for graphs with a few expensive ops (like convolutions), you may not see much speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.6259469399997215\n",
      "Function conv: 0.5865928770003848\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# Warm up\n",
    "conv_layer(image)\n",
    "conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing\n",
    "\n",
    "##### What is \"tracing\"?\n",
    "\n",
    "A `tf.function` runs program in a TensorFlow Graph. However, a `tf.Graph` cannot represent all the things that you'd write in an eager TensorFlor program. For instance, Python support polymorphism, but `tf.Graph` requires its inputs to have a specified data type and dimension. Or performan side tasks like reading command-line arguments, raising an error, or working with a more complex Python object; none of these things can run in a `tf.Graph`.\n",
    "\n",
    "`tf.function` bridges this gap by separating your code in two strages:\n",
    "\n",
    "1. In the first stage, referred to as **\"tracing\"**, `tf.function` creates a new `tf.Graph`. Python code runs normally, but all TensorFlow operations (like adding two Tensors) are *defered*: they are captured by the `tf.Graph` and not run.\n",
    "2. In the second stage, a `tf.Graph` which contains everything that was deferred in the first stage is run. This stage is much faster than the tracing stage.\n",
    "\n",
    "Depending on its inputs, `tf.function` will not always run the first stage when it is called (see `Rules of tracing`). Skipping the first stage and only executing the second stage is what gives TensorFlow's high performance.\n",
    "\n",
    "When `tf.function` does decide to trace, the tracing stage is immediately followed by the second stage, so calling the `tf.function` both creates and runs the `tf.Graph`.\n",
    "\n",
    "When passing arguments of different types into a `tf.function`, both stages are run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def double(a):\n",
    "    print(\"Tracing with\", a)\n",
    "    return a + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(double(tf.constant(1)))\n",
    "print()\n",
    "print(double(tf.constant(1.1)))\n",
    "print()\n",
    "print(double(tf.constant('a')))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `tf.function` repeatedly called with the same argument type, TensorFlow will skip the tracing stage and reuse a previously traced graph, as the generated graph would be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'bb', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# This doesn't print 'Tracing with ...'\n",
    "print(double(tf.constant(\"b\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pretty_printed_concrete_signatures` to see all the available traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Parameters:\n",
      "  a (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "Output Type:\n",
      "  TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "Captures:\n",
      "  None\n",
      "\n",
      "Input Parameters:\n",
      "  a (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
      "Output Type:\n",
      "  TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  None\n",
      "\n",
      "Input Parameters:\n",
      "  a (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(), dtype=tf.string, name=None)\n",
      "Output Type:\n",
      "  TensorSpec(shape=(), dtype=tf.string, name=None)\n",
      "Captures:\n",
      "  None\n"
     ]
    }
   ],
   "source": [
    "print(double.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.function` creates a cached, dynamic dispatch layer over TensorFlow's graph tracing logic.\n",
    "\n",
    "- A `tf.Graph` is the raw, language-agnostic, portable representation of a TensorFlow computation.\n",
    "- Tracing is the process through which new `tf.Graph`s are generated from Python code.\n",
    "- An instance of `tf.Graph` is specialized to the specific input types it was traced with. Differing types require retracing.\n",
    "- Each traced `tf.Graph` has a corresponding `ConcreteFunction`.\n",
    "- A `tf.function` manages a cache of `ConcreteFunction`s and picks the right one for your inputs.\n",
    "- `tf.function` wraps the Python function that will be traced, returning a `tf.types.experimental.PolymorphicFunction` object.\n",
    "\n",
    "##### Rules of tracing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
