# Inference

```
AI model in action
```

In AI, inference refers to the process where a trained machine learning model makes predictoins or draws conclusion from new, unseen data. Unlike training, inference involes the model applying what it has learned to make decisions without needing examples of the exact result. In essence, inference is the AI model actively functioning. For example, a self-driving car recognizing a stop sign on a read it has neven encountered before demonstrates instance. The model identifies the stop sign in a new setting, using its learned knowledge to make a decision in real-time.

### AI inference vs. training

- **Training** is the first phase of an AI model. Training may involve a process of trail and error, or a process of showing the model examples of the desired inputs and outputs, or both.
- **Inference** is the process that follows AI training. The better trained a model is, and the more fine-tuned it is, the better its inferences will be -- although they are never guaranteed to be perfect.

To get to the point of being able to identify stops signs in new locations (or predicts professions athlete's performance), machine learning models go through a process of training. FOr the autonomous vehicle, its developers showed the model thousands or millions of images of stop signs. A vehicle running the model may have even been driven on reads (with a human driver as backup), enabling it to learn from trail and error. Eventually, after enough training, the model was able to identify stops signs on its own.

### What are some use cases for AI inference?

Some of the most commonly used examples include:

- Large language models (LLMs): A model trained on sample text can parse and interpret texts it has never seen before.
- Prediction analytics: Once a model has been trained on past data and reaches the inference stage, it can make predictions based on incoming data.
- Email security: A machine learning model can be trained to recoginze spam emails or business email compromise attackes, then make inferences about incoming email messages, allowing security filters to block malicious ones.
- Driverless cars: As described in the above example, inference is hugely important for autonomous vehicles.
- Research: Scientific and medical research depends on interpreting data, and AI inference can be used to draw conclusions from the data.
- Finance: A model trained on part market performance can make (non-guaranteed) inferences about future market performance.