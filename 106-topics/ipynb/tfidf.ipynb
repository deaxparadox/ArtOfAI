{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Implementation\n",
    "\n",
    "- [Python](#python-implementation)\n",
    "- [Scikit-Learn](#tf-idf-using-scikit-learn)\n",
    "- [Tensorflow](#tf-idf-using-tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Implementation\n",
    "\n",
    "We will wrtie a TF-IDF function from scratch using the standard formula given above, but we will not apply any preprocessing operations such as top removal, stemming, punctuation removal, or lowercasing. Result may be different when using native function built into a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's contruct a small corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"data science is one of the most important fields of science\",\n",
    "    \"this is one of the best data science courese\",\n",
    "    \"data scientists analysze data\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a word set for the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the corpus: 14\n",
      "The words in the corpus: \n",
      " {'most', 'this', 'one', 'important', 'analysze', 'courese', 'data', 'best', 'fields', 'scientists', 'is', 'science', 'of', 'the'}\n"
     ]
    }
   ],
   "source": [
    "words_set = set()\n",
    "\n",
    "for doc in corpus:\n",
    "    words = doc.split(\" \")\n",
    "    words_set = words_set.union(set(words))\n",
    "    \n",
    "print(\"Number of words in the corpus:\", len(words_set))\n",
    "print(\"The words in the corpus: \\n\", words_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Term Frqeuency\n",
    "\n",
    "Now we can create a dataframe by the number of documents in the corpus and the word set, and use that information to compute the **term frequency (TF)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysze',\n",
       " 'best',\n",
       " 'courese',\n",
       " 'data',\n",
       " 'fields',\n",
       " 'important',\n",
       " 'is',\n",
       " 'most',\n",
       " 'of',\n",
       " 'one',\n",
       " 'science',\n",
       " 'scientists',\n",
       " 'the',\n",
       " 'this'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most</th>\n",
       "      <th>this</th>\n",
       "      <th>one</th>\n",
       "      <th>important</th>\n",
       "      <th>analysze</th>\n",
       "      <th>courese</th>\n",
       "      <th>data</th>\n",
       "      <th>best</th>\n",
       "      <th>fields</th>\n",
       "      <th>scientists</th>\n",
       "      <th>is</th>\n",
       "      <th>science</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       most      this       one  important  analysze   courese      data  \\\n",
       "0  0.090909  0.000000  0.090909   0.090909      0.00  0.000000  0.090909   \n",
       "1  0.000000  0.111111  0.111111   0.000000      0.00  0.111111  0.111111   \n",
       "2  0.000000  0.000000  0.000000   0.000000      0.25  0.000000  0.500000   \n",
       "\n",
       "       best    fields  scientists        is   science        of       the  \n",
       "0  0.000000  0.090909        0.00  0.090909  0.181818  0.181818  0.090909  \n",
       "1  0.111111  0.000000        0.00  0.111111  0.111111  0.111111  0.111111  \n",
       "2  0.000000  0.000000        0.25  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents in the corpus\n",
    "n_docs = len(corpus)\n",
    "\n",
    "# Number of unique words in the corpus\n",
    "n_words_set = len(words_set)\n",
    "\n",
    "df_tf = pd.DataFrame(\n",
    "    np.zeros((n_docs, n_words_set)),\n",
    "    columns=list(words_set)\n",
    ")\n",
    "\n",
    "\n",
    "# Compute Term Frequency (TF)\n",
    "for i in range(n_docs):\n",
    "    \n",
    "    # words in the document\n",
    "    words = corpus[i].split(\" \")\n",
    "    \n",
    "    for w in words:\n",
    "        df_tf[w][i] = df_tf[w][i] + (1 / len(words))    \n",
    "        \n",
    "        \n",
    "df_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe above shows we have a column for each word and a row each document. This shows the frequency of each word in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Inverse Document Freqency\n",
    "\n",
    "Now, we'll compute the **inverse document frequency (IDF)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of: \n",
      "           most: 0.47712125471966244\n",
      "           this: 0.47712125471966244\n",
      "            one: 0.17609125905568124\n",
      "      important: 0.47712125471966244\n",
      "       analysze: 0.47712125471966244\n",
      "        courese: 0.47712125471966244\n",
      "           data:        0.0\n",
      "           best: 0.47712125471966244\n",
      "         fields: 0.47712125471966244\n",
      "     scientists: 0.47712125471966244\n",
      "             is: 0.17609125905568124\n",
      "        science: 0.17609125905568124\n",
      "             of: 0.17609125905568124\n",
      "            the: 0.17609125905568124\n"
     ]
    }
   ],
   "source": [
    "print (\"IDF of: \")\n",
    "\n",
    "idf = {}\n",
    "\n",
    "for w in words_set:\n",
    "    # number of documents in the corpus that contain the word\n",
    "    k = 0\n",
    "    \n",
    "    for i in range(n_docs):\n",
    "        if w in corpus[i].split():\n",
    "            k+=1\n",
    "            \n",
    "    idf[w] = np.log10(n_docs/k)\n",
    "    \n",
    "    print(f\"{w:>15}: {idf[w]:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most</th>\n",
       "      <th>this</th>\n",
       "      <th>one</th>\n",
       "      <th>important</th>\n",
       "      <th>analysze</th>\n",
       "      <th>courese</th>\n",
       "      <th>data</th>\n",
       "      <th>best</th>\n",
       "      <th>fields</th>\n",
       "      <th>scientists</th>\n",
       "      <th>is</th>\n",
       "      <th>science</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.016008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       most      this       one  important  analysze   courese  data  \\\n",
       "0  0.043375  0.000000  0.016008   0.043375   0.00000  0.000000   0.0   \n",
       "1  0.000000  0.053013  0.019566   0.000000   0.00000  0.053013   0.0   \n",
       "2  0.000000  0.000000  0.000000   0.000000   0.11928  0.000000   0.0   \n",
       "\n",
       "       best    fields  scientists        is   science        of       the  \n",
       "0  0.000000  0.043375     0.00000  0.016008  0.032017  0.032017  0.016008  \n",
       "1  0.053013  0.000000     0.00000  0.019566  0.019566  0.019566  0.019566  \n",
       "2  0.000000  0.000000     0.11928  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = df_tf.copy()\n",
    "\n",
    "for w in words_set:\n",
    "    for i in range(n_docs):\n",
    "        df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "        \n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"data\" has an IDF of 0 because it appears in every document. As a result, is not considered to be an important term in this corpus. This will slightly in the following sklearn implementation, where \"data\" will be non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Using scikit-learn\n",
    "\n",
    "First, we need to import sklearn's TfidfVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to instantiate the class first, then we call the `fit_transform` method on our test corpus. This will perform all of the calculations we performed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t0.320895090271992\n",
      "  (0, 5)\t0.320895090271992\n",
      "  (0, 7)\t0.320895090271992\n",
      "  (0, 12)\t0.24404898736823682\n",
      "  (0, 8)\t0.48809797473647365\n",
      "  (0, 9)\t0.24404898736823682\n",
      "  (0, 6)\t0.24404898736823682\n",
      "  (0, 10)\t0.48809797473647365\n",
      "  (0, 3)\t0.18952580966166677\n",
      "  (1, 2)\t0.40029393442429256\n",
      "  (1, 1)\t0.40029393442429256\n",
      "  (1, 13)\t0.40029393442429256\n",
      "  (1, 12)\t0.30443385488725433\n",
      "  (1, 8)\t0.30443385488725433\n",
      "  (1, 9)\t0.30443385488725433\n",
      "  (1, 6)\t0.30443385488725433\n",
      "  (1, 10)\t0.30443385488725433\n",
      "  (1, 3)\t0.2364200460658773\n",
      "  (2, 0)\t0.5427006131762078\n",
      "  (2, 11)\t0.5427006131762078\n",
      "  (2, 3)\t0.6410554491745127\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vector = tf_idf_model.fit_transform(corpus)\n",
    "\n",
    "# print matrix cordinate with non-zero values\n",
    "print(tf_idf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After vectoring the corpus by the function, a [sparse matrix](../sparse-matrix.md) is obtained.\n",
    "\n",
    "Here's the current shape of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> (3, 14)\n"
     ]
    }
   ],
   "source": [
    "print(type(tf_idf_vector), tf_idf_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can convert to an regular array to get a better idea of the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.18952581 0.32089509 0.32089509\n",
      "  0.24404899 0.32089509 0.48809797 0.24404899 0.48809797 0.\n",
      "  0.24404899 0.        ]\n",
      " [0.         0.40029393 0.40029393 0.23642005 0.         0.\n",
      "  0.30443385 0.         0.30443385 0.30443385 0.30443385 0.\n",
      "  0.30443385 0.40029393]\n",
      " [0.54270061 0.         0.         0.64105545 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54270061\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_array = tf_idf_vector.toarray()\n",
    "\n",
    "print(tf_idf_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now very straightforward to obtain the original terms in the corpus by using `get_feature_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analysze' 'best' 'courese' 'data' 'fields' 'important' 'is' 'most' 'of'\n",
      " 'one' 'science' 'scientists' 'the' 'this']\n"
     ]
    }
   ],
   "source": [
    "words_set_features_name = tf_idf_model.get_feature_names_out()\n",
    "\n",
    "print(words_set_features_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll create a dataframe to better show the TF-IDF scores of each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_idf_2 = pd.DataFrame(tf_idf_array, columns=words_set_features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysze</th>\n",
       "      <th>best</th>\n",
       "      <th>courese</th>\n",
       "      <th>data</th>\n",
       "      <th>fields</th>\n",
       "      <th>important</th>\n",
       "      <th>is</th>\n",
       "      <th>most</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>science</th>\n",
       "      <th>scientists</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189526</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.236420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.400294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysze      best   courese      data    fields  important        is  \\\n",
       "0  0.000000  0.000000  0.000000  0.189526  0.320895   0.320895  0.244049   \n",
       "1  0.000000  0.400294  0.400294  0.236420  0.000000   0.000000  0.304434   \n",
       "2  0.542701  0.000000  0.000000  0.641055  0.000000   0.000000  0.000000   \n",
       "\n",
       "       most        of       one   science  scientists       the      this  \n",
       "0  0.320895  0.488098  0.244049  0.488098    0.000000  0.244049  0.000000  \n",
       "1  0.000000  0.304434  0.304434  0.304434    0.000000  0.304434  0.400294  \n",
       "2  0.000000  0.000000  0.000000  0.000000    0.542701  0.000000  0.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency** in tensorflow in calculate using the following formula:\n",
    "\n",
    "```\n",
    "idf = 1 + log((corpus size + 1) / (count of documents containing term + 1)).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91930\\Documents\\github-deaxparadox\\ArtOfAI\\venv\\artofai\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-kernel-1",
   "language": "python",
   "name": "ai-kernel-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
